{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jili0434/5703/blob/main/5703API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade openai"
      ],
      "metadata": {
        "id": "rbqrwtEKIuFv",
        "outputId": "61fd5e32-a6ee-4eb4-f805-bc874126bb14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "rbqrwtEKIuFv",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.70.0)\n",
            "Collecting openai\n",
            "  Downloading openai-1.72.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
            "Downloading openai-1.72.0-py3-none-any.whl (643 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m643.9/643.9 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.70.0\n",
            "    Uninstalling openai-1.70.0:\n",
            "      Successfully uninstalled openai-1.70.0\n",
            "Successfully installed openai-1.72.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "09e018a7",
      "metadata": {
        "id": "09e018a7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sqlalchemy import create_engine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "import xgboost as xgb\n",
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# client = OpenAI(api_key=\"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\")"
      ],
      "metadata": {
        "id": "5BzZiqB1sEgL"
      },
      "id": "5BzZiqB1sEgL",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "9b9cfb0a",
      "metadata": {
        "id": "9b9cfb0a",
        "outputId": "7a49f6e4-98e4-48af-c8c5-db98bb66cceb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API key is valid!\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  models = openai.models.list()\n",
        "  print(\"API key is valid!\")\n",
        "except Exception as e:\n",
        "  print(\"Error in API Key\", e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "00fa7f7e",
      "metadata": {
        "id": "00fa7f7e"
      },
      "outputs": [],
      "source": [
        "completion = client.chat.completions.create(\n",
        "    model = 'gpt-3.5-turbo',\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \" You're a career planner, and the next answers are all going to be answered from a career planner's perspective. \"},\n",
        "        {\"role\": \"user\", \"content\": \"I am entp, please give me my suitable career planning advice\"}\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cff24e81",
      "metadata": {
        "id": "cff24e81",
        "outputId": "77fe6d76-d15e-4e12-b256-31779c7e0d16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "As an ENTP (Extroverted, Intuitive, Thinking, Perceiving) personality type, you likely possess traits such as creativity, innovation, and adaptability. Here are some career planning advice tailored for an ENTP:\n",
            "\n",
            "1. **Explore Diverse Career Paths:** Due to your curious and versatile nature, you may excel in a variety of fields. Consider exploring careers in entrepreneurship, marketing, consulting, technology, or creative industries where you can utilize your problem-solving skills.\n",
            "\n",
            "2. **Seek Intellectual Stimulation:** Look for roles that challenge you intellectually and allow you to think on your feet. Consider positions that involve brainstorming, strategizing, and coming up with innovative solutions to complex problems.\n",
            "\n",
            "3. **Networking is Key:** Leverage your extroverted nature to build a strong professional network. Attend industry events, connect with like-minded professionals, and seek mentorship opportunities to expand your horizons and open up new career possibilities.\n",
            "\n",
            "4. **Embrace Change:** As a Perceiver, you thrive in dynamic environments. Pursue careers that offer variety, growth opportunities, and the chance to continually learn and adapt. Avoid overly structured or routine-based roles that may stifle your creativity.\n",
            "\n",
            "5. **Develop Your Communication Skills:** Work on honing your communication skills, both verbal and written, as they are essential for conveying your ideas effectively and gaining buy-in from others. Consider taking courses or workshops to enhance your presentation and negotiation skills.\n",
            "\n",
            "6. **Balance Creativity with Execution:** While your creativity is a strength, make sure to balance it with the ability to follow through on projects and bring ideas to fruition. Developing project management skills can be beneficial in ensuring your innovative ideas are successfully implemented.\n",
            "\n",
            "By focusing on these key areas and aligning your career choices with your strengths and preferences as an ENTP, you can build a fulfilling and successful professional path. Consider working with a career coach or counselor to further explore your options and create a strategic career plan tailored to your unique personality and goals.\n"
          ]
        }
      ],
      "source": [
        "print(completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76ef071b-2df6-4703-aa0c-3dea4638932b",
      "metadata": {
        "id": "76ef071b-2df6-4703-aa0c-3dea4638932b"
      },
      "source": [
        "# A rough modeling framework that will connect to a database and process the data, then train AI models and use GPT's API interface\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "064864f8-0942-4d71-a6e4-9bf814cc4c31",
      "metadata": {
        "id": "064864f8-0942-4d71-a6e4-9bf814cc4c31"
      },
      "outputs": [],
      "source": [
        "#Connecting to the database\n",
        "engine = create_engine('mysql+pymysql://user:password@host:port/database')\n",
        "\n",
        "# load data\n",
        "query = 'SELECT * FROM career_survey_data'\n",
        "data = pd.read_sql(query, engine)\n",
        "\n",
        "\n",
        "# Step 2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# 'recommended_career'\n",
        "X = data.drop('recommended_career', axis=1)\n",
        "y = data['recommended_career']\n",
        "\n",
        "#\n",
        "for column in X.select_dtypes(include=['object']).columns:\n",
        "    le = LabelEncoder()\n",
        "    X[column] = le.fit_transform(X[column])\n",
        "\n",
        "# divided dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Step 3: train model\n",
        "\n",
        "model = xgb.XGBClassifier(n_estimators=100, max_depth=6, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# Step 4:\n",
        "\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "print(classification_report(y_test, predictions))\n",
        "\n",
        "\n",
        "# Step 5:\n",
        "\n",
        "openai.api_key = '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'\n",
        "\n",
        "def enhanced_career_recommendation(user_features):\n",
        "    # predict ml model\n",
        "    initial_recommendation = model.predict(user_features)\n",
        "\n",
        "    #\n",
        "    prompt = f\"Based on the following user characteristics:{user_features.to_dict()}\\nPreliminary recommendations for careers have been made:{initial_recommendation}\\nPlease provide more detailed career advice:\"\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4-turbo\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "\n",
        "# example\n",
        "sample_user_features = X_test.iloc[0:1]\n",
        "detailed_recommendation = enhanced_career_recommendation(sample_user_features)\n",
        "print(detailed_recommendation)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Updated model**\n",
        "\n",
        "**Key Improvements:**\n",
        "\n",
        "​Complete English Localization:\n",
        "\n",
        "* Maintained clear section headers for readability\n",
        "\n",
        "​Enhanced Documentation:\n",
        "\n",
        "* Added detailed docstrings for all functions/methods\n",
        "Included Args/Returns documentation\n",
        "* Added class-level documentation\n",
        "\n",
        "​Optimized Prompt Engineering:\n",
        "\n",
        "* Structured GPT prompt for better analysis\n",
        "* Added clear response formatting requirements\n",
        "* Balanced creativity with temperature=0.7\n",
        "\n",
        "​Error Handling:\n",
        "\n",
        "* Maintained try-except block for API calls\n",
        "* Added descriptive error messages\n",
        "\n",
        "​Configuration Notes:\n",
        "\n",
        "* Added parameter explanations (temperature, max_tokens)\n",
        "\n",
        "​Maintainability:\n",
        "\n",
        "* Consistent naming conventions\n",
        "* Logical code organization\n",
        "* Clear separation of concerns\n",
        "\n",
        "Better readability for international teams\n",
        "\n",
        "More structured AI responses\n",
        "\n",
        "Easier maintenance and extension\n",
        "\n",
        "Comprehensive documentation\n",
        "\n",
        "Robust error handling"
      ],
      "metadata": {
        "id": "w6FYhB62tw4B"
      },
      "id": "w6FYhB62tw4B"
    },
    {
      "cell_type": "code",
      "source": [
        "#Eason's version of predicted model\n",
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sqlalchemy import create_engine\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "import xgboost as xgb\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from openai import OpenAI  # Using the new SDK\n",
        "\n",
        "# 1. Data Loading and Basic Preprocessing\n",
        "def load_data():\n",
        "    \"\"\"\n",
        "    Load data from MySQL database and perform initial cleaning\n",
        "    Returns:\n",
        "        pd.DataFrame: Cleaned dataset\n",
        "    \"\"\"\n",
        "    engine = create_engine('mysql+pymysql://user:password@host:port/database')\n",
        "    query = '''SELECT * FROM career_survey_data\n",
        "               WHERE recommended_career IS NOT NULL'''  # Filter out null values\n",
        "    data = pd.read_sql(query, engine)\n",
        "\n",
        "    # Data cleaning\n",
        "    data = data.drop_duplicates()\n",
        "    numeric_cols = data.select_dtypes(include=np.number).columns\n",
        "    data[numeric_cols] = data[numeric_cols].fillna(data[numeric_cols].median())\n",
        "\n",
        "    return data\n",
        "\n",
        "# 2. Advanced Feature Engineering\n",
        "def feature_engineering(data):\n",
        "    \"\"\"\n",
        "    Create new features to improve model performance\n",
        "    Args:\n",
        "        data (pd.DataFrame): Input dataset\n",
        "    Returns:\n",
        "        pd.DataFrame: Enhanced dataset with new features\n",
        "    \"\"\"\n",
        "    # Create interaction feature\n",
        "    data['skill_interaction'] = data['technical_skill'] * data['communication_skill']\n",
        "    # Create age bins\n",
        "    data['age_group'] = pd.cut(data['age'], bins=[20,30,40,50,60],\n",
        "                              labels=['20-30','31-40','41-50','51-60'])\n",
        "    return data\n",
        "\n",
        "# 3. Optimized Data Preprocessing Pipeline\n",
        "def preprocess_data(data):\n",
        "    \"\"\"\n",
        "    Create preprocessing pipeline for different feature types\n",
        "    Args:\n",
        "        data (pd.DataFrame): Input dataset\n",
        "    Returns:\n",
        "        ColumnTransformer: Configured preprocessing pipeline\n",
        "    \"\"\"\n",
        "    # Identify feature types\n",
        "    categorical_features = data.select_dtypes(include=['object', 'category']).columns.drop('recommended_career')\n",
        "    numeric_features = data.select_dtypes(include=np.number).columns\n",
        "\n",
        "    # Build preprocessing pipeline\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', StandardScaler(), numeric_features),  # Scale numeric features\n",
        "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)  # Encode categorical\n",
        "        ])\n",
        "\n",
        "    return preprocessor\n",
        "\n",
        "# 4. Model Training with Hyperparameter Tuning\n",
        "def train_model(X, y):\n",
        "    \"\"\"\n",
        "    Train XGBoost classifier with hyperparameter optimization\n",
        "    Args:\n",
        "        X (pd.DataFrame): Features\n",
        "        y (pd.Series): Target variable\n",
        "    Returns:\n",
        "        sklearn.Pipeline: Best trained model\n",
        "    \"\"\"\n",
        "    # Define parameter grid for tuning\n",
        "    param_grid = {\n",
        "        'model__n_estimators': [100, 200],\n",
        "        'model__max_depth': [3, 6, 9],\n",
        "        'model__learning_rate': [0.01, 0.1, 0.3]\n",
        "    }\n",
        "\n",
        "    # Build model pipeline\n",
        "    pipeline = Pipeline(steps=[\n",
        "        ('preprocessor', preprocess_data(data)),  # Reuse preprocessing\n",
        "        ('smote', SMOTE(random_state=42)),        # Handle class imbalance\n",
        "        ('model', xgb.XGBClassifier(\n",
        "            objective='multi:softprob',\n",
        "            eval_metric='mlogloss',\n",
        "            early_stopping_rounds=10,\n",
        "            random_state=42))\n",
        "    ])\n",
        "\n",
        "    # Configure cross-validation\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "    # Perform grid search\n",
        "    grid_search = GridSearchCV(\n",
        "        pipeline, param_grid, cv=cv,\n",
        "        scoring='f1_weighted', n_jobs=-1, verbose=1)\n",
        "\n",
        "    grid_search.fit(X, y)\n",
        "\n",
        "    return grid_search.best_estimator_\n",
        "\n",
        "# 5. Enhanced GPT Integration Module\n",
        "class CareerAdvisor:\n",
        "    \"\"\"\n",
        "    Class for generating AI-powered career recommendations\n",
        "    Combines ML predictions with GPT-4 analysis\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize OpenAI client with API key\"\"\"\n",
        "        self.client = OpenAI(api_key='your-api-key-here')  # Initialize with your key\n",
        "\n",
        "    def generate_prompt(self, features, prediction):\n",
        "        \"\"\"\n",
        "        Create structured prompt for GPT-4\n",
        "        Args:\n",
        "            features (pd.Series): User characteristics\n",
        "            prediction (str): ML model's career prediction\n",
        "        Returns:\n",
        "            str: Formatted prompt\n",
        "        \"\"\"\n",
        "        return f\"\"\"As a career planning expert, provide development advice based on:\n",
        "\n",
        "        User Profile:\n",
        "        {features.to_dict()}\n",
        "\n",
        "        Predicted Career: {prediction}\n",
        "\n",
        "        Structure your response with:\n",
        "        1. Core strengths alignment analysis\n",
        "        2. 3 specific development paths\n",
        "        3. Key skill areas needing improvement\n",
        "        4. Industry trend relevance\"\"\"\n",
        "\n",
        "    def get_recommendation(self, features):\n",
        "        \"\"\"\n",
        "        Generate AI-enhanced career recommendation\n",
        "        Args:\n",
        "            features (pd.DataFrame): User feature vector\n",
        "        Returns:\n",
        "            str: Detailed career advice\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Get ML prediction\n",
        "            prediction = model.predict(features)[0]\n",
        "            prompt = self.generate_prompt(features.iloc[0], prediction)\n",
        "\n",
        "            # Get GPT-4 analysis\n",
        "            response = self.client.chat.completions.create(\n",
        "                model=\"gpt-4-turbo\",\n",
        "                messages=[{\n",
        "                    \"role\": \"system\",\n",
        "                    \"content\": \"You're a senior career advisor skilled at data-driven recommendations.\"\n",
        "                }, {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": prompt\n",
        "                }],\n",
        "                temperature=0.7,  # Balance creativity/focus\n",
        "                max_tokens=500    # Control response length\n",
        "            )\n",
        "            return response.choices[0].message.content\n",
        "        except Exception as e:\n",
        "            return f\"Error generating recommendation: {str(e)}\"\n",
        "\n",
        "# Main Execution Flow\n",
        "if __name__ == \"__main__\":\n",
        "    # Load and prepare data\n",
        "    data = load_data()\n",
        "    data = feature_engineering(data)\n",
        "\n",
        "    # Split into features/target\n",
        "    X = data.drop('recommended_career', axis=1)\n",
        "    y = data['recommended_career']\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Train model\n",
        "    model = train_model(X_train, y_train)\n",
        "\n",
        "    # Evaluate model\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # Initialize advisor\n",
        "    advisor = CareerAdvisor()\n",
        "\n",
        "    # Generate sample recommendation\n",
        "    sample = X_test.sample(1)\n",
        "    print(advisor.get_recommendation(sample))"
      ],
      "metadata": {
        "id": "VitA66O4tIVo"
      },
      "id": "VitA66O4tIVo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NTKNDGsRv5f7"
      },
      "id": "NTKNDGsRv5f7",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}